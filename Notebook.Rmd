---
title: "Determining Insurance Policyholder Value"
author: "Ted Zybin, Rohit Nair, Ibrahim Alwishah"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  pdf: default
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE, 
                      results = "hide",
                      warning = FALSE,
                      message = FALSE
                      )

# to override these defaults to make a certain chunk's output show up
# you need to write results="markup" in that particular cell opening, 
# so for instance your cell would look like this
#
# ```{r results = "markup"}
# code whose _output_ you want to see
# ```
```

## External Requirements

```{r}

# libraries

library("tidyr")
library("dplyr")
library("ggplot2")
library("mosaic")

# data
insurance_data <- read.csv("Insurance_policy.csv")
```

```{r results = "markup"}
knitr::kable(head(insurance_data))
```

## Data Preparation

### Count and Remove Some Missing Values as Appropriate (NAs)

```{r results = "markup"}
dim(insurance_data);
# summary to see if there are any missing values
summary(insurance_data);
# number of missing values in a clearer fashion
colSums( is.na(insurance_data) );
# how many rows have 0 NAs
sum( complete.cases(insurance_data) );
# how many rows are incomplete?
sum( !complete.cases(insurance_data) )
```

### Data Transformation

```{r results = "markup"}
# check that all relevant variables are factors
str(insurance_data);
# setting marital status, occupation, and value flag as factors
insurance_data$marital_status = as.factor(insurance_data$marital_status);
insurance_data$occupation = as.factor(insurance_data$occupation);
insurance_data$value_flag = as.factor(insurance_data$value_flag);
str(insurance_data)
```
```{r results = "markup"}
# filtering out individuals less than 25 years of age and with a cap gain of 0.
num_df <- insurance_data %>%
  select(age,education_num,cap_gain,
         hours_per_week,score) %>%
  filter(age >= 25, cap_gain != 0) %>%
  arrange(age)

# all data fields for the studied population
all_df <- insurance_data %>%
  select(age,education_num,marital_status,
         occupation,cap_gain,hours_per_week,score,value_flag) %>%
  filter(age >= 25, cap_gain != 0)
```

## Research Question

How do the provided variables associate with the prediction that a
customer is of high value and what model provides a feasible baseline
accuracy using the most important, if not all, variables for the
aforementioned prediction?

## Introduction

Risk assessment is a critical aspect of the insurance industry, as it
allows companies to accurately assess the likelihood of a policyholder
filing a claim and to set premiums accordingly. By identifying high
value policyholders, insurance companies can prioritize providing them
with the best possible products and services, leading to increased
customer satisfaction and loyalty. Additionally, accurately predicting
which policyholders are likely to be low value can help the company make
informed decisions about which potential customers to accept or reject.
This can help the company avoid accepting high-risk policyholders who
are likely to file costly claims, ultimately leading to improved
financial performance. Marginal improvements in risk assessment
techniques can therefore have a significant impact on the overall
success of an insurance company.

In this study, we will explore the relationship between various
predictor variables and the target variable of whether an individual is
considered a "high value" or "low value" policyholder by an insurance
company. We have been provided with data on past policyholders,
including their age, level of education, marital status, occupation,
capital gains, hours worked per week, and an insurance score. Using this
data, we will construct a model that can accurately predict whether a
prospective policyholder will be of high or low value to the company.
While predictive accuracy is of utmost importance, we will also strive
to interpret our results in a way that makes intuitive sense. For the
purposes of this analysis, we will only consider individuals who are 25
years of age or older.

Based on the data provided, the factors of interest include:

-   The age of the prospective policyholder

-   A numerical indicator of the amount of education that a policyholder
    has
    
-   Marital status of the policyholder

-   Occupation of the policyholder

-   Capital gains recorded on the investments of the policyholder

-   The number of hours worked per week by the policyholder

-   The proprietary insurance score of the policyholder

Furthermore, we can synthesize new variables from the existing ones that
would prove useful in ultimately predicting that value of a potential
policyholder.

-   The ratio of capital gains to hours worked per week, which could
    provide insight into the policyholder's investment habits and
    financial success.

-   A variable which captures the effect of increasing age on the value 
    of education

-   Use regression analysis to derive a predictive model that
    incorporates all of the existing predictor variables, which would
    allow us to identify the relative importance of each variable and
    potentially create a new, composite variable that represents the
    combined effect of all predictors.

Before deriving insights from associations implied by the models used,
it is important to condense the data using useful statistical summaries.
Summary statistics will provide valuable information about the
distribution of the data and the overall spread of the values within
each variable. For example, the mean and standard deviation can be used
to identify any potential outliers in the data, while the range can
provide a sense of the overall variability within the data.
Additionally, comparing the summary statistics for each variable can
help identify any potential relationships or patterns within the data.
These summary statistics can be used to inform the development of the
predictive model, as well as to interpret and understand the results of
the analysis.

## Data Set Description

The data set has 48842 rows and 8 columns, above it also shows the mean and max 
of different categories using the 'summary' function. The data set also does not
have NAs or incomplete rows.

This data set contains information for an unspecified insurance provider. The 
data recorded is categorized by age, education number which is a score that is 
a numerical value given based of their level of education, marital status, 
occupation, capital gain on investments, and value flag which is an integer of 
a high value customer 
and low value customer.

The variables used in the data are age which is a numerical variable that is 
taken in years, education number is a numerical value showing the level of 
education of the customer, marital status is a seven level variable that tell 
us their relationship status, occupation is 6 split into 6 groups that there is 
no specific meaning to except the sixth group which indicates the occupation is 
not known, capital gain is a numerical value that is recording on investments, 
and hours per week which is a number recorded in hours of the amount of work 
customers work. 

## Exploratory Data Analysis

### Descriptive Statistics

-   Present the data in different types of tables, diagrams, and find
    all descriptive stats (mean, median, mode, std.dev, etc.,)
-   3 numerical summary tables and 3 graphs

#### Numerical Summary I

```{r results="markup"}
favstats_vec = c()
columns = colnames(num_df)

total_favstats = data.frame()

# row binding favstats for each column in num_df
for (i in 1:ncol(num_df)){
  total_favstats <- rbind(total_favstats, favstats(num_df[,i]))
}

# column binding variable names
total_favstats <- cbind(names = columns, total_favstats)
rownames(total_favstats) <- NULL

total_favstats
```

#### Numerical Summary II
```{r results="markup"}
num_sum <- insurance_data %>%
  filter(age >= 25, cap_gain > 0) %>%
  summarize(
    avg_education_num = mean(education_num),
    avg_cap_gain = mean(cap_gain)
  )
knitr::kable(summary(data))
```


### Visualization

### Average Score vs. Age
```{r}
# Graph used to compare age and average score.
# If you notice the variability it may be due to the short range on the y-axis

all_df %>%
  group_by(age) %>%
  summarize(Average_score_by_age = mean(score, na.rm = T)) %>%
  ggplot(aes(x = age, y=Average_score_by_age)) +
  geom_line(color = "red") +
  ggtitle("Average Score Vs. Age")+
  xlab("Age") +
  ylab("Average Score")
```

The idea behind this graph is to show how age may play a part in someone's score. 
Since the insurance score is a proprietary value, it is expected to highlight 
policyholder trustworthiness. It was assumed that middle-aged policyholders 
would have a higher score. However, this was not the case. The line plays an 
optical illusion which makes this seem as though it is very static while if you 
play close attention the y-axis is ranging from 59-61.5, so the average score 
does not have much variance but only appeases that way because of how the graph 
is skewed. To go in deeper depth taking a look at the people at the older ages 
where we see the variability, there rent many to record on, this causes the 
average to be seen as skewed. We can deduct from this that the average score 
when taking into account age does not play a major role in the data as there 
isn't any major changes in the average score


### Distribution of Policyholder Scores by Occupation
```{r}
scores_by_value_flag <- all_df %>%
  filter(age >= 25) %>%
  select(occupation,score,value_flag) %>%
  mutate_at(vars(occupation,value_flag),list(factor))

# boxplot showing distribution of scores by occupation
ggplot(scores_by_value_flag, aes(x=occupation, y=score)) +
  geom_boxplot(aes(fill=value_flag))+
  xlab("Occupation (in Categorical Groups)") +
  ylab("Insurance Scores") +
  ggtitle("Distribution of Scores by Occupation")
```

The graph above explicates the association between type of occupation and score 
according to the value flag they were labeled with. It’s shown that the median 
scores for all types of occupations never go above 60 for those labeled with 
low. As this graph is plotting the categorical variable of occupation group 
against numerical variable insurance score, we see that the insurance score 
plays an important part in choosing a high value client. The groups that we 
categorized by the value of high rather than low always had a insurance score 
higher than the low value client. This can help us infer that with a higher 
insurance score comes a higher likely hood that the client is a high value one.

### Value Flags by Age, Based on Education
```{r}
# getting value_flag counts for individuals of a certain age and occupation
age_value_by_occupation <- all_df %>%
  filter(age >= 25) %>%
  select(age,occupation,value_flag) %>%
  group_by(value_flag,occupation,age) %>%
  summarize(count=count(value_flag == "High"| value_flag == "Low"))
# facet wrap
ggplot(data = age_value_by_occupation, mapping =
         aes(x = age, y = count, color = value_flag)) +
  geom_point() +
  xlab("Age (Years)") +
  ylab("count of Value_Flag") +
  ggtitle("Value_Flag by Age, based on Occupation") +
  facet_wrap(~occupation, nrow=2)
```

The graph above looks at the total incidence of each value_flag at all ages 
present in dataset, while divided into facets based on the type of occupation. 
For Groups 1-3, there’s a higher number of people classified as low for the 
bulk of the recorded ages. Groups 4, 5, and NA, all do not seem to have much 
variablity.Group 4 shows the high and low value flagged clients mixed together, 
and the same can be said about group NA. We can conclude from these graphs
that the age does not play a major role in the groups when observing the values 
flags of clients.

### Synthesis of New Variables
```{r}
all_data <- all_df %>%
  mutate(cap_hours_ratio = cap_gain/hours_per_week) %>%
  select(age,education_num, cap_gain, hours_per_week,cap_hours_ratio,value_flag)

head(all_data)
```

## Analysis
The analysis begins with a confidence interval analysis, to study the the 
effects that capital gains and age have on the value flag of clients. The 
principle components of this data set are:

 1. Age
 2. Education number
 3. Marital status
 4. occupation
 5. capital gain
 6. Hours per week
 7. Score
 8. Value Flag
 9. Capital Gains to Hours Per Week Ratio
 
 
Out of these components of the data set the population of age and capital gain 
is focused on to conclude if they play a rule in the categorizing a client as 
high value. 

### Bootstrap Confidence Interval

Our bootstrap confidence interval is taken on individuals older than or equal 
to the age 25 and have a capital gain greater than 0 USD, with a high value 
flag. We were given a population size of 2462.

```{r results="markup"}
population <- df %>%
  filter(age >= 25, cap_gain > 0, value_flag == "High") 

ggplot(population, aes(x = cap_gain)) + 
  geom_density() + 
  ggtitle("Population Distribution of Capital Gains") + 
  xlab("Capital Gain") + 
  ylab("Density")
```
 
The graph shows the skew we have with the capital gain. We can infer that there 
is not much variability after 25000 for capital gain, although we do see a small 
spike when reaching 100000.


```{r results="markup"}
set.seed(101)
# select a sample, without replacement
sample = population %>%
sample_n(size = 200,replace = FALSE)

bootstrap_samplemeans <- do(1000)*mean(~cap_gain,
data = sample_n(population,size = 200,
replace = TRUE))
bootstrap_samplemeans <- bootstrap_samplemeans %>%
rename(boostrap_samplemeans = mean)
head(bootstrap_samplemeans)
```

In the chart above we see the estimated summary taken on the sample population 
of those over the age of 25 who's capital gain is greater than 0. This data can 
be used to calculate errors and perform hypothesis test to further support our 
research.



### Hypothesis Testing

The average capital gains value within a sample of this population is assumed 
to be greater than $20000 USD. Is this supported by the data?

H0 : The average capital gains amount for an individual equal to or above the 
age of 25 flagged as being high value is equal to $20000.

Ha : The average capital gains amount for an individual equal to or above the 
age of 25 flagged as being high value is not equal to $20000.

H0 : µ = 20000

Ha : µ != 20000

To compute the p-value, we assume that the null hypothesis is true and we’ll 
set the significance level at 5%.

```{r results = "markup"}
# claimed value of the mean
omean <- 20000
# store the current sample
sample_cap_gains <- sample$cap_gain
# compute the sample mean
mean_sample <- mean(sample_cap_gains)
mean_sample
```

```{r results = "markup"}
# store the error in estimating the average capital gains for the sample
# distance between null value and sample mean
c <- abs(omean - mean_sample)

```


```{r results = "markup"}
new_cap_gains <- sample_cap_gains - mean_sample + 20000

mean(new_cap_gains)

```

```{r results = "markup"}
both <- data.frame(sample_cap_gains,new_cap_gains)

bootstrap <- do(1000)*mean(~new_cap_gains,
data = sample_n(both,
size = nrow(both),
replace = T))

p_value <- sum(bootstrap$mean >= mean_sample)/1000

cat("p-value is equal to:",p_value)
```

Since the p-value is greater than 0.05, We fail to reject the null hypothesis. 
The data do not provide convincing evidence at the .05 significance level that 
the average capital gains value is not equal to 20000. As we fail to reject the 
null hypothesis, it is feasible to assume that those that are older than 25 and 
a high value policyholder are likely to have an average capital gain of $20000. 
The information we have now can be used to conclude that age and capital gain 
do play a role in predicting high value clients. The variable that we focus on 
with the test would be age in years greater than 25 and a capital gain greater 
than 0.

### Regression Models

The regression models shown are both taken on education levels and show the 
variability that education level gives when predicting a high value client and
a low client.

This graph below shows that a higher education level is often times a high value 
client. We see that by taking the average education level and plot it against 
age we have a line of best fit that shows a linear increase for education level 
of high value clients. While in the same graph we a see a negative linear line 
that shows education level is less in low value clients 


``` {r results="markup"}
# find relationship between age and education_num
age_data <- all_data %>%
  group_by(age,value_flag) %>%
  summarize(avg_ed_num = mean(education_num))

# 70 - 30 train test split
train_test_split <- sample(c(TRUE,FALSE), nrow(age_data),replace=TRUE, 
                           prob=c(0.7,0.3))

train_data <- age_data[train_test_split,]
test_data <- age_data[!train_test_split,]

# regression model (High)
train_data_high <- train_data %>%
  filter(value_flag=="High")

high_model = lm(train_data_high$avg_ed_num ~ train_data_high$age, data = 
                  train_data_high)

# regression model (Low)
train_data_low <- train_data %>%
  filter(value_flag=="Low")

low_model = lm(train_data_low$avg_ed_num ~ train_data_low$age, data =
                train_data_low)


# fitted plot on test_data
ggplot(test_data,aes(x=age,y=avg_ed_num, color=value_flag))+
  geom_point() +
  xlab("Age of Policyholder") +
  ylab("Average Education Level") +
  geom_abline(intercept = high_model$coefficients[1],
              slope = high_model$coefficients[2],
              color = "red") +
  geom_abline(intercept = low_model$coefficients[1],
              slope = low_model$coefficients[2],
              color = "blue")

# evaluation
test_data_high <- test_data %>%
  filter(value_flag == "High")
test_data_low <- test_data %>%
  filter(value_flag == "Low")

mse_high = mean( (test_data_high$avg_ed_num - predict(high_model, newdata  = test_data_high))^2  )
mse_low = mean( (test_data_low$avg_ed_num - predict(low_model, newdata = test_data_low))^2 )

mse_high
mse_low
```

## Using a Support Vector Machine Model

In order to synthesize the provided data and get a feasible predictive model, 
we can use an SVM model. SVM models can handle high-dimensional data, making 
them well-suited for situations where there are many predictor variables. 
In the insurance industry, policyholders may have many different characteristics 
that could affect their value, such as their age, education level, occupation, 
and insurance score. An SVM model could help to accurately predict the value of 
a policyholder based on these variables.

SVM models can provide high predictive accuracy, which is important for the 
marketing department of an insurance company. By accurately predicting the 
value of a policyholder, the marketing department can make more informed 
decisions about which prospective customers to target, leading to higher 
profits for the company.

SVM models are known for their ability to handle data with complex, 
non-linear relationships between the variables. In the insurance industry, 
the relationships between the predictor variables and the target variable 
(policyholder value) are likely to be complex and non-linear. An SVM model 
could help to accurately capture these relationships and make accurate predictions.

SVM models are robust to noise and outliers in the data, which can be common 
in real-world datasets. In the insurance industry, the data on policyholders 
is likely to be noisy and contain outliers, such as policyholders with 
unusually high or low values. An SVM model could help to accurately predict 
the value of policyholders even in the presence of noise and outliers.

Ultimately, using an SVM model could be beneficial for an insurance company 
because it can handle high-dimensional data with complex, non-linear 
relationships, provide high predictive accuracy, and be robust to noise 
and outliers in the data. These qualities could help the marketing department 
of the insurance company to make more informed decisions about which prospective 
customers to target, leading to higher profits for the company.

## Discussion + Conclusion

This is a general overview of what risk assessment for an insurance policyholder 
would look like. With the data provided, we were able to select pertinent 
variables,both numerical and categorical, and identify the various associations 
between the variables which would contribute to the predictions of a policyholder 
being high or low value. Graphs were made to further analyze patterns. Bootstrap 
hypothesis testing was used to look at sample distributions of capital gains and
affirm its connection to value flagging. The association between level of 
education and capital gains also was explored in order to ascertain their 
relative weights within a possible prediction model. In the end, based on the 
nature of the variables provided and the associations found, a support vector 
machine model was used to predict whether a potential customer would be high or 
low value.
	The most important part of our project was to trace any relationship between 
the flag status of a client and other variables presented in the table.  
But why is it essential to identify high-value customers? Here are presented 
several reasons to look for high value customers: 	
  - Knowing your high-value customers helps you to plan ahead and make better 
decisions about future projects.
  - You can maximize their value and develop longer-lasting relationships.
  - You can focus your marketing and acquisition strategies on similar customers 
using lookalike audiences.
  - Delighting these customers can create a positive feedback loop, where they 
bring in more business for your company.

We noticed that there is a relationship between the flag status of a client 
and his/her education level. Clients, whose degree was higher than 10, were 
considered to be «high» value clients. Despite the fact that the insurance 
company made some exceptions, it would be right to say that the agents of the 
insurance company have a specific algorithm, which helps them group their 
clients with respect to the level of their degree.  Besides, it was proven that 
clients with a score less than 61 tend to be considered as low value clients.	

Apart from that, our team conducted a test hypothesis. Our initial hypothesis 
was that the average capital gains amount for an individual equal to or above 
the age of 25 flagged as being high value equals $20000, while the alternative 
hypothesis claimed that the average capital gains amount for an individual equal 
to or above the age of 25 flagged as being high value does not equal $20000. 
As we did the test, p-value turned out to be more that 0.05 and that gave us 
enough evidence to claim that the initial hypothesis should be accepted. In 
other words, we had enough statistical evidence to assume that those who are 
older than 25 and are considered to be high value are likely to have an 
average capital gain of $20000. The information we have now can be used to 
conclude that age and capital gain do play a role in predicting high value 
clients. 

As an answer to our research question, we think that it is essential to say 
that there are different factors and variables that associate with a prediction 
that a random customer would be considered a high value client. Arguments like 
age,education level and score play a crucial role for the insurance company and 
clients’ status. Other variables like marital status, occupation, capital gain 
and working hours per week are also taken into consideration by agents of the 
insurance company, but are considered to be less important. 

## References

- "Introduction to Machine Learning with R" by Brett Lantz
- RDocumentation - e1071 (version 1.7-12)


