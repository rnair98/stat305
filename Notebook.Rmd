---
title: "Determining Insurance Policyholder Value"
author: "Ted Zybin, Rohit Nair, Ibrahim Alwishah"
date:   "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE, 
                      results = "hide",
                      warning = FALSE,
                      message = FALSE
                      )

# to override these defaults to make a certain chunk's output show up
# you need to write results="markup" in that particular cell opening, 
# so for instance your cell would look like this
#
# ```{r results = "markup"}
# code whose _output_ you want to see
# ```
```

## External Requirements

```{r}

# libraries

library("tidyr")
library("dplyr")
library("ggplot2")
library("mosaic")

# data
insurance_data <- read.csv("Insurance_policy.csv")
```

```{r}
knitr::kable(head(insurance_data))
```

## Data Preparation

### Count and Remove Some Missing Values as Appropriate (NAs)

```{r}
dim(insurance_data);
# summary to see if there are any missing values
summary(insurance_data);
# number of missing values in a clearer fashion
colSums( is.na(insurance_data) );
# how many rows have 0 NAs
sum( complete.cases(insurance_data) );
# how many rows are incomplete?
sum( !complete.cases(insurance_data) )
```

### Data Transformation

```{r}
# check that all relevant variables are factors
str(insurance_data);
# setting marital status, occupation, and value flag as factors
insurance_data$marital_status = as.factor(insurance_data$marital_status);
insurance_data$occupation = as.factor(insurance_data$occupation);
insurance_data$value_flag = as.factor(insurance_data$value_flag);
str(insurance_data)
```
```{r}
# filtering out individuals less than 25 years of age and with a cap gain of 0.
num_df <- insurance_data %>%
  select(age,education_num,cap_gain,
         hours_per_week,score) %>%
  filter(age >= 25, cap_gain != 0) %>%
  arrange(age)

# all data fields for the studied population
all_df <- insurance_data %>%
  select(age,education_num,marital_status,
         occupation,cap_gain,hours_per_week,score,value_flag) %>%
  filter(age >= 25, cap_gain != 0)
```

## Research Question

How do the provided variables associate with the prediction that a
customer is of high value and what model provides a feasible baseline
accuracy using the most important, if not all, variables for the
aforementioned prediction?

## Introduction

Risk assessment is a critical aspect of the insurance industry, as it
allows companies to accurately assess the likelihood of a policyholder
filing a claim and to set premiums accordingly. By identifying high
value policyholders, insurance companies can prioritize providing them
with the best possible products and services, leading to increased
customer satisfaction and loyalty. Additionally, accurately predicting
which policyholders are likely to be low value can help the company make
informed decisions about which potential customers to accept or reject.
This can help the company avoid accepting high-risk policyholders who
are likely to file costly claims, ultimately leading to improved
financial performance. Marginal improvements in risk assessment
techniques can therefore have a significant impact on the overall
success of an insurance company.

In this study, we will explore the relationship between various
predictor variables and the target variable of whether an individual is
considered a "high value" or "low value" policyholder by an insurance
company. We have been provided with data on past policyholders,
including their age, level of education, marital status, occupation,
capital gains, hours worked per week, and an insurance score. Using this
data, we will construct a model that can accurately predict whether a
prospective policyholder will be of high or low value to the company.
While predictive accuracy is of utmost importance, we will also strive
to interpret our results in a way that makes intuitive sense. For the
purposes of this analysis, we will only consider individuals who are 25
years of age or older.

Based on the data provided, the factors of interest include:

-   The age of the prospective policyholder

-   A numerical indicator of the amount of education that a policyholder
    has
    
-   Marital status of the policyholder

-   Occupation of the policyholder

-   Capital gains recorded on the investments of the policyholder

-   The number of hours worked per week by the policyholder

-   The proprietary insurance score of the policyholder

Furthermore, we can synthesize new variables from the existing ones that
would prove useful in ultimately predicting that value of a potential
policyholder.

-   The ratio of capital gains to hours worked per week, which could
    provide insight into the policyholder's investment habits and
    financial success.

-   A variable which captures the effect of increasing age on the value
    of education

-   Use regression analysis to derive a predictive model that
    incorporates all of the existing predictor variables, which would
    allow us to identify the relative importance of each variable and
    potentially create a new, composite variable that represents the
    combined effect of all predictors.

Before deriving insights from associations implied by the models used,
it is important to condense the data using useful statistical summaries.
Summary statistics will provide valuable information about the
distribution of the data and the overall spread of the values within
each variable. For example, the mean and standard deviation can be used
to identify any potential outliers in the data, while the range can
provide a sense of the overall variability within the data.
Additionally, comparing the summary statistics for each variable can
help identify any potential relationships or patterns within the data.
These summary statistics can be used to inform the development of the
predictive model, as well as to interpret and understand the results of
the analysis.

**Insert a general summary of why we're using a bootstrap confidence
interval and doing hypothesis testing**

**Insert Explanation of Models ---\> (Ultimately, a summary of why we
chose to use a support vector machine for multiclass classification over
other ML models to predict policyholder value)**


## Data Set Description

The data set has 48842 rows and 8 columns, above it also shows the mean and max 
of different categories using the 'summary' function. The data set also does not
have NAs or incomplete rows.

This data set contains information for an unspecified insurance provider. The data 
recorded is categorized by age, education number which is a score that is a numerical 
value given based of their level of education, marital status, occupation, capital 
gain on investments, and value flag which is an integer of a high value customer 
and low value customer.

The variables used in the data are age which is a numerical variable that is taken 
in years, education number is a numerical value showing the level of education of 
the customer, marital status is a seven level variable that tell us their relationship 
status, occupation is 6 split into 6 groups that there is no specific meaning to except 
the sixth group which indicates the occupation is not known, capital gain is a numerical 
value that is recording on investments, and hours per week which is a number recorded 
in hours of the amount of work customers work. 

## Exploratory Data Analysis

### Descriptive Statistics

-   Present the data in different types of tables, diagrams, and find
    all descriptive stats (mean, median, mode, std.dev, etc.,)
-   3 numerical summary tables and 3 graphs

```{r results="markup"}
favstats_vec = c()
columns = colnames(num_df)

total_favstats = data.frame()

# row binding favstats for each column in num_df
for (i in 1:ncol(num_df)){
  total_favstats <- rbind(total_favstats, favstats(num_df[,i]))
}

# column binding variable names
total_favstats <- cbind(names = columns, total_favstats)
rownames(total_favstats) <- NULL

total_favstats
```




### Visualization

-   Identify the scientific questions we can ask about the data.
-   Create new variables & information given the existing variables in
    the dataset.
-   Write custom functions to transform data
-   3 graphs

#### Distribution of Policyholder Scores by Occupation
```{r}
scores_by_value_flag <- df %>%
  filter(age >= 25) %>%
  select(occupation,score,value_flag) %>%
  mutate_at(vars(occupation,value_flag),list(factor))

# boxplot showing distribution of scores by occupation
ggplot(scores_by_valueflag, aes(x=occupation, y=score)) +
  geom_boxplot(aes(fill=value_flag))+
  xlab("Occupation (in Categorical Groups)") +
  ylab("Insurance Scores") +
  ggtitle("Distribution of Scores by Occupation")
```


#### Value Flags by Age, Based on Occupation


### Analysis

-   Discuss at least one bootstrap confidence interval, at least one
    hypothesis test, and two linear models trained on all the data
    (include at least one scatter-plot with a regression line). Compare
    the two linear models in terms of test mean square error (train both
    using the same subset of all the data called training data, and form
    the test mean square error using the rest of the data, called test
    data).
    
#### Bootstrap Confidence Interval



    
```{r warning=FALSE}


data <- insurance_data %>% 
  group_by(hours_per_week, value_flag) %>%
  summarise(scoreHoursperWeek = mean(score))

model <- lm(data$scoreHoursperWeek ~ data$hours_per_week)


data %>%
  ggplot() +
  geom_point(aes(x = hours_per_week, 
                 y = scoreHoursperWeek, color = value_flag)) +
  labs(title = "Age of people with insurance versus education number",
       x = "Hours Worked Per Week", y = "Score") +
  geom_abline(intercept = model$coefficients[1],
              slope = model$coefficients[2], 
              color="red")
```

## Discussion + Conclusion

-   Write a clear description of the results from the previous sections.
    Do not forget to address the research questions that you posed in
    the introduction section. Make sure to pose possible questions based
    on graphs, tables, and other inferential results.

## References

-   List of all books, journals, web sites, videos referenced.
-   Use footnotes for in-line references (see sample project)

## Appendix

-   All code goes here.
